{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Tractable's ML Classifier Workshop!\n",
    "\n",
    "[Tractable linkedIn](https://www.linkedin.com/company/tractable/) | [Anifah](https://www.linkedin.com/in/anifah-bhadmus-891a7a116/) | [Martha](https://www.linkedin.com/in/martha-rose-robinson-14567a40/) | [Wei Ann](https://www.linkedin.com/in/weiann-heng/)\n",
    "\n",
    "Today, we will use industry-standard techniques to build a Machine Learning (ML) Classifier using supervised learning. \n",
    "\n",
    "We will use our classifier to classify vehicles by type (car, truck, SUV, van). Supervised learning means that we have test data that we can compare our results to. \n",
    "\n",
    "Start with: A dataset that gives us images (input) and labels (teaching signal/feedback). \n",
    "End with: An array of 4 numbers for each of those images (i.e. their classification confidences!)\n",
    "\n",
    "1. Create training, validation, and test data sets\n",
    "2. Build a data pipeline\n",
    "3. Explore a pre-trained model\n",
    "4. Perform feature extraction to get classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before we start\n",
    "1. Housekeeping \n",
    "2. How to use Jupyter notebook\n",
    "3. Quick concepts\n",
    "\n",
    "### Neural network\n",
    "Source: IBM\n",
    "\n",
    "<img src=\"https://1.cms.s81c.com/sites/default/files/2021-01-06/ICLH_Diagram_Batch_01_03-DeepNeuralNetwork-WHITEBG.png\" alt=\"neural-network\" width=\"500px\">\n",
    "\n",
    "### Feature \n",
    "An individual measureable property/characteristic. These are usually numeric, but we can think of some qualitative examples\n",
    "\n",
    "[Source](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.nosimpler.me%2Fmachine-learning%2F&psig=AOvVaw1i03lInhxU-kNY9Y2zn59a&ust=1619104334232000&source=images&cd=vfe&ved=0CAoQjRxqFwoTCJiZg-jPj_ACFQAAAAAdAAAAABAJ)\n",
    "<img src=\"https://www.nosimpler.me/wp-content/uploads/2016/08/ml-features-1.jpg\" alt=\"feature\" width=\"400px\">\n",
    "\n",
    "### Classifier\n",
    "A classifier is the thing that we train to classify data into classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3c358ee073bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from workshop_utils import extract_data, get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create our datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal: Create a training, validation, and test dataset from available data\n",
    "\n",
    "#### Input: \n",
    "Stanford Cars196 dataset (Dataset citation: 3D Object Representations for Fine-Grained Categorization. Jonathan Krause, Michael Stark, Jia Deng, Li Fei-Fei. 4th IEEE Workshop on 3D Representation and Recognition, at ICCV 2013 (3dRR-13). Sydney, Australia. Dec. 8, 2013.)\n",
    "\n",
    "TODO: more information about input: files and labels (0,1,2,3 which correspond to car, truck, SUV, van)\n",
    "\n",
    "\n",
    "#### Output:\n",
    "3 datasets (training, validation, test) that generate batches of images and class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract compressed dataseet\n",
    "extract_data()\n",
    "\n",
    "# Function to convert files into an matrix 2D images and labels.\n",
    "# Each 2D image is made out of 3 channels \n",
    "def load_data(path, label):\n",
    "    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n",
    "    return image, label\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(get_data('train'))\n",
    "train_dataset = train_dataset.map(load_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's take a peep at this dataset using our load_data function\n",
    "fig, axarr = plt.subplots(2, 5, figsize=(10, 5))\n",
    "axes = axarr.flatten()\n",
    "for i, (image, label) in enumerate(train_dataset.take(10)):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(image.numpy())\n",
    "    ax.set_title(int(label))\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 3 datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(get_data('train')).map(load_data)\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(get_data('val')).map(load_data)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(get_data('test')).map(load_data)\n",
    "\n",
    "\n",
    "# Batch size = number of training exmaples utilized in one iteration. Important to not over/underfit\n",
    "batch_size = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.cache().batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.cache().batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.cache().batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "print(image_batch.shape)\n",
    "print(label_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal: Create augmented data set to improve training\n",
    "\n",
    "#### Input: \n",
    "Training dataset from previous section\n",
    "\n",
    "#### Output:\n",
    "Larger training data set with augmentation?? (this isn't actually true - we are just showing what the augumented data looks like, discuss with team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using tensorflow library\n",
    "from tf.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Link to library https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing\n",
    "# CODE-ALONG CHECKPOINT 1 - use tf.keras to pre-process images\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  preprocessing.?,\n",
    "  preprocessing.?,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_dataset.take(1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    first_image = images[0]\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = data_augmentation(\n",
    "            tf.expand_dims(first_image, 0), training=True\n",
    "        )\n",
    "        plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
    "        plt.title(int(labels[0]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How does a pre-trained model perform?\n",
    "\n",
    "### Goal: Test how good Google's pre-trained MobileNet V2 model is at classifying vehicles out of the box\n",
    "\n",
    "This is an example of how real world AI applications are built - use pre-trained model rather than building from scratch. Won't go into too much detail\n",
    "\n",
    "#### Input: \n",
    "1. Google's MobileNet V2 model, which is pre-trained on ImageNet dataset with a wide variety of categories (not just vehicles, but things like food, people, etc)\n",
    "2. Our training Cars196 dataset\n",
    "\n",
    "#### Output:\n",
    "\n",
    "The images of each vehicle and what MobileNet thinks this image is. (Remember that this model is general, so will not output 0,1,2,3 like you might expect.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-24de1bf7ea9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mIMG_SHAPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreprocess_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobilenet_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmobilenet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMobileNetV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMG_SHAPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = (160, 160, 3)\n",
    "\n",
    "# Prepare data to suit MobileNet's expected input\n",
    "# Weights trained on imagenet\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "mobilenet_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, weights='imagenet')\n",
    "\n",
    "# Create a tf.Keras model based on our inputs and MobileNet\n",
    "input_layer = tf.keras.Input(shape=IMG_SHAPE)\n",
    "# We don't use this next line anywhere else, will check with team and remove\n",
    "preprocessed_input_layer = preprocess_input(input_layer)\n",
    "mobilenet_layer = mobilenet_model(preprocessed_inputs)\n",
    "model = tf.keras.Model(input_layer, mobilenet_layer)\n",
    "\n",
    "# Get model's predictions on our previously created image batch\n",
    "prediction_batch = model(image_batch)\n",
    "\n",
    "# Decode these predictions into human-readable class names (from imagenet)\n",
    "decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(prediction_batch.numpy(), top=1)\n",
    "\n",
    "fig, axarr = plt.subplots(8, 4, figsize=(10,20))\n",
    "axes = axarr.flatten()\n",
    "for i, (image, prediction) in enumerate(zip(image_batch, decoded_predictions)):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(image.numpy())\n",
    "    top_label = prediction[0][1]\n",
    "    score = prediction[0][2]\n",
    "    ax.set_title(f'{top_label}, {score:.2f}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature extraction\n",
    "\n",
    "### Goal: Use an existing model to extract features from our images, and transfer that knowledge to our new task\n",
    "\n",
    "*Use mobilenet v2 to extract useful visual features and build a new classifier on top*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Diagram of what we're trying to do. Feature extractor and what we're trying to get out, classifier head and how that accepts features.\n",
    "# What bits we will train.\n",
    "# Step through entire plan before we write any code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step by step runthrough:\n",
    "1. Create a base model from the pre-trained model MobileNet V2 and change it's output from classifications to features\n",
    "2. Create a \"feature extractor\" that converts a visual image into a block of features\n",
    "3. Generate predictions from these blocks of features. (need more explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Create the base model from the pre-trained model MobileNet V2 and change it's output from classifications to features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature extractor converts each 160x160x3 image into a 5x5x1280 block of features. Let's see what it does to an example batch of images:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (160, 160, 3)\n",
    "# CODE-ALONG CHECKPOINT 2\n",
    "base_model = ?\n",
    "# make it untrainable\n",
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the base model architecture\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 2 - Create a \"feature extractor\" that converts a visual image into a block of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extractor converts 160x160x3 image into a 5x5x1280 block of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b6388557f32a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# feature_batch = ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(?)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeature_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "\n",
    "# CODE-ALONG CHECKPOINT 2\n",
    "feature_batch = ?\n",
    "print(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### STEP 3 - Generate predictions from these blocks of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, we need to generate predictions from these blocks of features. \n",
    "First, create a layer to average over the 5x5 spatial locations, creating a single 1280 vector per image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a fully-connected layer of neurons as our outputs for our 4 classes. Each output neuron should be connected to each of the 1280 neurons in the previous layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE-ALONG CHECKPOINT 4 - Create a fully connected output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's connect all our parts together to build our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE-ALONG CHECKPOINT 5 - Define our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model before training it. We need to pick a learning rate, an optimiser, a loss function, and any metrics we want to track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually train the model!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate prior to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Car', 'SUV', 'Truck', 'Van']\n",
    "fig, axarr = plt.subplots(8, 4, figsize=(10,20))\n",
    "axes = axarr.flatten()\n",
    "for i, (image, prediction) in enumerate(zip(image_batch, predictions)):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(image)\n",
    "    top_label = np.argmax(prediction)\n",
    "    ax.set_title(f'{class_names[top_label]}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is your challenge.\n",
    "\n",
    "In feature extraction, we were training a small number of new layers on top of the existing MobileNetV2 base model. The weights of that base model were not updated during training.\n",
    "\n",
    "One way to increase performance further is to \"fine-tune\" the model, by training the weights of the top layers of the base model alongside our classification layer. This processes should force the weights of the base model to move from defining generic feature maps to features more specific for our task.\n",
    "\n",
    "(Note, if you try this without first training the top-level classifier with the base model set to non-trainable, the graident updates will be very large (because the classifier starts off with random weights) and your base model is likely to forget what it has already learned).\n",
    "\n",
    "There are quite a few hyperparameters to change here -- how many layers to allow fine-tuning for, what learning rate to use, etc. We've set you up with a starting point, but play around and see how much you can improve performance with fine-tuning. We will have a prize for the best improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un-freeze the top layers of the model\n",
    "All you need to do is unfreeze the base_model and set the bottom layers to be un-trainable. Then, you should recompile the model (necessary for these changes to take effect), and resume training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate/10),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "len(model.trainable_variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue training the model - if trained to convergence earlier this will improve your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print('Test accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Car', 'SUV', 'Truck', 'Van']\n",
    "fig, axarr = plt.subplots(8, 4, figsize=(10,20))\n",
    "axes = axarr.flatten()\n",
    "for i, (image, prediction) in enumerate(zip(image_batch, predictions)):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(image)\n",
    "    top_label = np.argmax(prediction)\n",
    "    score = prediction[top_label]\n",
    "    ax.set_title(f'{class_names[top_label]}, {score:.2f}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}